# -*- coding: utf-8 -*-
"""SubtaskC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uyYfXZ718rg-xx78VGT-v6sRk-WlkgBi

# **Subtask C**
"""

# Commented out IPython magic to ensure Python compatibility.
import spacy
import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
sns.set()
from sklearn import preprocessing, linear_model, model_selection, neighbors, svm, naive_bayes, metrics, tree
from spacy import displacy
from spacy.tokenizer import Tokenizer
from spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex
import re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from sklearn.preprocessing import LabelEncoder

# instantiates the spacy language module
nlp = spacy.load("en_core_web_sm")

# call and display the dataframe
tweets_df = pd.read_csv('drive/My Drive/OLIDv1.0/olid-training-v1.0.tsv', delimiter="\t")
tweets_df.head()

# size of the dataset
len(tweets_df)

# changes the dataframe index to the tweet id
tweets_df = tweets_df.set_index('id')

# display information about the dataframe
tweets_df.info()

# storing dtype before operation 
dtype_before = type(tweets_df["tweet"]) 
  
# converting to list 
tweet_list = tweets_df["tweet"].tolist() 
  
# storing dtype after operation 
dtype_after = type(tweet_list) 

# stores the tweets in a list
doc = nlp(tweet_list[0])

# shows the first tweet in the list
doc

# shows the tweet split up into indivdual sections
[token.text for token in doc]

"""**Pre-processing the Dataset**"""

tweets_df.drop(['subtask_a', 'subtask_b'], axis = 1, inplace = True, errors = 'ignore')
tweets_df.head()

tweets_df = tweets_df.dropna()

tweets_df.head()

le = LabelEncoder()
tweets_df['subtask_c'] = le.fit_transform(tweets_df['subtask_c']) 
tweets_df.head()

#1=individual
#2=other
#3=group

# method that will remove @USER tags from the data
def remove_pattern(input_txt, pattern):
  r = re.findall(pattern, input_txt)
  for i in r:
    input_txt = re.sub(i, '', input_txt)

  return input_txt

# tags are removed and a new dataset without them is saved
tweets_df['tweet'] = np.vectorize(remove_pattern)(tweets_df['tweet'], "@[\w]*")

# URL links had been changes to 'URL' so they have been removed as they're unnecessary
tweets_df['tweet'] = np.vectorize(remove_pattern)(tweets_df['tweet'], "URL")

# removes useless emoticons and punctuation
tweets_df['tweet'] = tweets_df['tweet'].str.replace("[^a-zA-Z#']", " " )

# displays the processed data without tags, URL or useless punctuation
tweets_df.head()

barData = pd.read_csv('drive/My Drive/OLIDv1.0/olid-training-v1.0.tsv', delimiter="\t")
sns.countplot(x = 'subtask_c',  data = barData, palette = 'magma')
plt.ylabel('Number of Tweets')
plt.xlabel('Tweet Classification')
plt.title('The Target of the Tweet')
plt.show()

"""**Machine Learning using the Bag-of-Words Method**"""

from sklearn.feature_extraction.text import CountVectorizer
# create a count vector to extract the words as bag-of-words
bow_vect = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')
# transform the tweets into the vectorisation
bow = bow_vect.fit_transform(tweets_df['tweet'])

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import f1_score

# create the training and testing bag-of-words
train_bow = bow[:13240, :] #31962
test_bow = bow[13240:, :]

# set up a training and testing split 
xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(train_bow, tweets_df['subtask_c'], random_state=42, test_size=0.2)

# instantiate the logistic regression function
lreg = LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=9999)
lreg.fit(xtrain_bow, ytrain)

# set up the predictions
prediction = lreg.predict_proba(xvalid_bow)
prediction_int = prediction[:,2] >= 0.3
prediction_int = prediction_int.astype(np.int)

# calculate the baseline accuracy
baseline_predictions = [1 for x in yvalid]
metrics.accuracy_score(yvalid, baseline_predictions)

# display the logistic regression f1 prediction
f1_score(yvalid, prediction_int, average='macro')

# prediction accuracy
metrics.accuracy_score(yvalid, prediction_int)

# set up a heatmap to visualise the predictions of the logistic regression algorithm
cm = metrics.confusion_matrix(yvalid, prediction_int)#, labels = [1,0,2])
fig, ax = plt.subplots()
sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm',cbar=False, ax=ax)
#ax.set_xticklabels(['Group','Individual', 'Other'])
#ax.set_yticklabels(['Group','Individual', 'Other'])
ax.set_xlabel('Predicted Class')
ax.set_title('Heatmap Showing the Predictions for the Logistic Regression Algorithm using Bag-of-Words.')
# I had to offset the ylim because matplotlib's newest update has caused them to go wonky otherwise
#ax.set_ylim([0,2])
ax.set_ylabel('True Class');

# instantiate some machine learning functions
classifiers = [neighbors.KNeighborsClassifier(),
               naive_bayes.MultinomialNB(),
               linear_model.LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=9999),
               tree.DecisionTreeClassifier(),
               linear_model.SGDClassifier(loss="log", penalty="l2", max_iter=50),
               MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
               beta_2=0.999, early_stopping=False, epsilon=1e-08,
               hidden_layer_sizes=(20, 20, 20), learning_rate='constant',
               learning_rate_init=0.001, max_iter=500, momentum=0.9,
               nesterovs_momentum=True, power_t=0.5, random_state=None,
               shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
               verbose=False, warm_start=False)]

classifier_names = ['KNN','Multinomial NB','Logistic', 'Decision Tree', 'SGD', 'MLP']
accuracies_bow = []
f1_bow = []
macro_bow = []
# iterate through the loop, training and fitting the tweet data
for clf, name in zip(classifiers,classifier_names):
    clf.fit(xtrain_bow, ytrain)
    prediction = clf.predict_proba(xvalid_bow)
    prediction_int = prediction[:,1] >= 0.3
    prediction_int = prediction_int.astype(np.int)
    acc = metrics.accuracy_score(yvalid, prediction_int)
    accuracies_bow.append(acc)
    f1 = f1_score(yvalid, prediction_int, average='weighted')
    f1_bow.append(f1)
    macro = f1_score(yvalid, prediction_int, average='macro')
    macro_bow.append(macro)
# save the accuracies in a DataFrame
models_bow = pd.DataFrame({'Model':classifier_names, 'Accuracy Baseline':accuracies_bow})

# save the f1 scores to a dataframe
models_bow_f1 = pd.DataFrame({'Model':classifier_names, 'F1 Baseline':f1_bow})

"""**Machine Learning using the TF-IDF Method**"""

from sklearn.feature_extraction.text import TfidfVectorizer
# create a count vector to extract the words as TF-IDF
tfidf_vect = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')
# transform the tweets into the vectorisation
tfidf = tfidf_vect.fit_transform(tweets_df['tweet'])

# create the training and testing tfidf sets
train_tfidf = tfidf[:13240, :] #31962
test_tfidf = tfidf[13240:, :]

# set up a training and testing split 
xtrain_tfidf, xvalid_tfidf, ytrain_tfidf, yvalid_tfidf = train_test_split(train_tfidf, tweets_df['subtask_c'], random_state=42, test_size=0.2)

# instantiate the logistic regression function
lreg = LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=9999)
lreg.fit(xtrain_tfidf, ytrain_tfidf)

# set up the predictions
prediction = lreg.predict_proba(xvalid_tfidf)
prediction_int = prediction[:,1] >= 0.3
prediction_int = prediction_int.astype(np.int)

# display the model accuracy
metrics.accuracy_score(yvalid_tfidf, prediction_int)

# display the logistic regression f1 prediction
f1_score(yvalid_tfidf, prediction_int, average='macro')

# set up a heatmap to visualise the predictions of the logistic regression algorithm
cm = metrics.confusion_matrix(yvalid_tfidf, prediction_int)#, labels = [1,0,2])
fig, ax = plt.subplots()
sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm',cbar=False, ax=ax)
##ax.set_xticklabels(['Group','Individual', 'Other'])
ax.set_yticklabels(['Group','Individual', 'Other'])
ax.set_xlabel('Predicted Class')
ax.set_title('Heatmap Showing the Predictions for the Logistic Regression Algorithm using TF-IDF.')
# I had to offset the ylim because matplotlib's newest update has caused them to go wonky otherwise
#ax.set_ylim([0,2])
ax.set_ylabel('True Class');

# instantiate some machine learning functions
classifiers = [neighbors.KNeighborsClassifier(),
               naive_bayes.MultinomialNB(),
               linear_model.LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=9999),
               tree.DecisionTreeClassifier(),
               linear_model.SGDClassifier(loss="log", penalty="l2", max_iter=50),
               MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
               beta_2=0.999, early_stopping=False, epsilon=1e-08,
               hidden_layer_sizes=(20, 20, 20), learning_rate='constant',
               learning_rate_init=0.001, max_iter=500, momentum=0.9,
               nesterovs_momentum=True, power_t=0.5, random_state=None,
               shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
               verbose=False, warm_start=False)]

classifier_names = ['KNN','Multinomial NB','Logistic', 'Decision Tree', 'SGD', 'MLP']
accuracies_tfidf = []
tfidf_f1 = []
tfidf_macro = []
# iterate through the loop, training and fitting the tweet data
for clf, name in zip(classifiers,classifier_names):
    clf.fit(xtrain_tfidf, ytrain_tfidf)
    prediction = clf.predict_proba(xvalid_tfidf)
    prediction_int = prediction[:,1] >= 0.3
    prediction_int = prediction_int.astype(np.int)
    acc = metrics.accuracy_score(yvalid_tfidf, prediction_int)
    accuracies_tfidf.append(acc)
    f1 = f1_score(yvalid_tfidf, prediction_int, average='weighted')
    tfidf_f1.append(f1)
    macro = f1_score(yvalid_tfidf, prediction_int, average='macro')
    tfidf_macro.append(macro)
# save the accuracies in a DataFrame
models_tfidf = pd.DataFrame({'Model':classifier_names, 'Accuracy Baseline':accuracies_tfidf})

# f1 scores
models_tfidf = pd.DataFrame({'Model':classifier_names, 'F1 Baseline':tfidf_f1})

# accuracies of the algorithms for the two methods
models = pd.DataFrame({'Model':classifier_names, 'Bag-of-Words Accuracy':accuracies_bow, 'TF-IDF Accuracy':accuracies_tfidf})

models_all = pd.DataFrame({'Model':classifier_names, 'BoW Accuracy': accuracies_bow, 'TF-IDF Accuracy': accuracies_tfidf, 'BoW F1':f1_bow, 'TF-IDF F1':tfidf_f1, 'BoW Macro F1':macro_bow, 'TF-IDF Macro F1':tfidf_macro})

# comparison between the f1 scores and accuracies of all algorithms between the two methods
models_all

"""**Maximum Absolute Scaling of the Bag-of-Words Data**"""

scalerminmax = preprocessing.MaxAbsScaler()
scalerminmax.fit(xtrain_bow)
X_train_scaled_minmax_bow = scalerminmax.transform(xtrain_bow)
X_train_scaled_minmax_bow[0]

# instantiate some machine learning functions
classifiers = [neighbors.KNeighborsClassifier(),
               naive_bayes.MultinomialNB(),
               linear_model.LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=9999),
               tree.DecisionTreeClassifier(),
               linear_model.SGDClassifier(loss="log", penalty="l2", max_iter=50),
               MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
               beta_2=0.999, early_stopping=False, epsilon=1e-08,
               hidden_layer_sizes=(20, 20, 20), learning_rate='constant',
               learning_rate_init=0.001, max_iter=500, momentum=0.9,
               nesterovs_momentum=True, power_t=0.5, random_state=None,
               shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
               verbose=False, warm_start=False)]

classifier_names = ['KNN','Multinomial NB','Logistic', 'Decision Tree', 'SGD', 'MLP']
X_valid_scaled_normal_bow = scalerminmax.transform(xvalid_bow)
accuracies_bow_normal = []
f1_bow_normal = []
macro_bow_normal = []
# iterate through the loop, training and fitting the tweet data
for clf, name in zip(classifiers,classifier_names):
    clf.fit(X_train_scaled_minmax_bow, ytrain)
    prediction = clf.predict_proba(X_valid_scaled_normal_bow)
    prediction_int = prediction[:,1] >= 0.3
    prediction_int = prediction_int.astype(np.int)
    acc_bow_max = metrics.accuracy_score(yvalid, prediction_int)
    accuracies_bow_normal.append(acc_bow_max)
    f1_bow_max = f1_score(yvalid, prediction_int, average='weighted')
    f1_bow_normal.append(f1_bow_max)
    macro_bow_norm = f1_score(yvalid, prediction_int, average='macro')
    macro_bow_normal.append(macro_bow_norm)
# save the accuracies in a DataFrame
models_bow_normal = pd.DataFrame({'model':classifier_names, 'MaxAbScaled':accuracies_bow_normal})    
#models_bow_normal

"""**Standardisation of the Bag-of-Words Data**"""

# scale the data using standardisation
scaler = preprocessing.StandardScaler(with_mean=False)
scaler.fit(xtrain_bow)
# transform and scale the data
X_train_standard_bow = scaler.transform(xtrain_bow)
X_train_standard_bow[0]

# instantiate some machine learning functions
classifiers = [neighbors.KNeighborsClassifier(),
               naive_bayes.MultinomialNB(),
               linear_model.LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=9999),
               tree.DecisionTreeClassifier(),
               linear_model.SGDClassifier(loss="log", penalty="l2", max_iter=50),
               MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
               beta_2=0.999, early_stopping=False, epsilon=1e-08,
               hidden_layer_sizes=(20, 20, 20), learning_rate='constant',
               learning_rate_init=0.001, max_iter=500, momentum=0.9,
               nesterovs_momentum=True, power_t=0.5, random_state=None,
               shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
               verbose=False, warm_start=False)]

classifier_names = ['KNN','Multinomial NB','Logistic', 'Decision Tree', 'SGD', 'MLP']
X_valid_scaled_standard_bow = scaler.transform(xvalid_bow)
accuracies_bow_standard = []
f1_bow_standard = []
macro_bow_standard = []
# iterate through the loop, training and fitting the tweet data
for clf, name in zip(classifiers,classifier_names):
    clf.fit(X_train_standard_bow, ytrain)
    prediction = clf.predict_proba(X_valid_scaled_standard_bow)
    prediction_int = prediction[:,1] >= 0.3
    prediction_int = prediction_int.astype(np.int)
    acc_bow_stan = metrics.accuracy_score(yvalid, prediction_int)
    accuracies_bow_standard.append(acc_bow_stan)
    f1_bow_stan = f1_score(yvalid, prediction_int, average='weighted')
    f1_bow_standard.append(f1_bow_stan)
    macro_bow_stan = f1_score(yvalid, prediction_int, average='macro')
    macro_bow_standard.append(macro_bow_stan)
# save the accuracies in a DataFrame
models_tfidf_bow = pd.DataFrame({'model':classifier_names, 'standard':accuracies_bow_standard})    
#models_tfidf_bow

"""**Maximum Absolute Scaling of the TF-IDF Data**"""

# scale the training data with maximum absolute scaling
scalerminmax = preprocessing.MaxAbsScaler()
scalerminmax.fit(xtrain_tfidf)
# transfrom and scale the data
X_train_scaled_minmax_tfidf = scalerminmax.transform(xtrain_tfidf)
X_train_scaled_minmax_tfidf[0]

# instantiate some machine learning functions
classifiers = [neighbors.KNeighborsClassifier(),
               naive_bayes.MultinomialNB(),
               linear_model.LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=9999),
               tree.DecisionTreeClassifier(),
               linear_model.SGDClassifier(loss="log", penalty="l2", max_iter=50),
               MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
               beta_2=0.999, early_stopping=False, epsilon=1e-08,
               hidden_layer_sizes=(20, 20, 20), learning_rate='constant',
               learning_rate_init=0.001, max_iter=500, momentum=0.9,
               nesterovs_momentum=True, power_t=0.5, random_state=None,
               shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
               verbose=False, warm_start=False)]

classifier_names = ['KNN','Multinomial NB','Logistic', 'Decision Tree', 'SGD', 'MLP']
X_valid_scaled_normal_tfidf = scalerminmax.transform(xvalid_tfidf)
accuracies_tfidf_normal = []
f1_tfidf_normal = []
macro_tfidf_normal = []
# iterate through the loop, training and fitting the tweet data
for clf, name in zip(classifiers,classifier_names):
    clf.fit(X_train_scaled_minmax_tfidf, ytrain_tfidf)
    # find the results
    prediction = clf.predict_proba(X_valid_scaled_normal_tfidf)
    prediction_int = prediction[:,1] >= 0.3
    prediction_int = prediction_int.astype(np.int)
    acc_tfidf_max = metrics.accuracy_score(yvalid_tfidf, prediction_int)
    accuracies_tfidf_normal.append(acc_tfidf_max)
    f1_tfidf_max = f1_score(yvalid_tfidf, prediction_int, average='weighted')
    f1_tfidf_normal.append(f1_tfidf_max)
    macro_tfidf_norm = f1_score(yvalid_tfidf, prediction_int, average='macro')
    macro_tfidf_normal.append(macro_tfidf_norm)
# save the accuracies in a DataFrame
models_tfidf_normal = pd.DataFrame({'model':classifier_names, 'MaxAbScaled':accuracies_tfidf_normal})    
#models_tfidf_normal

"""**Standardisation of the TF-IDF Data**"""

scaler = preprocessing.StandardScaler(with_mean=False)
scaler.fit(xtrain_tfidf)
X_train_standard = scaler.transform(xtrain_tfidf)
X_train_standard[0]

# instantiate some machine learning functions
classifiers = [neighbors.KNeighborsClassifier(),
               naive_bayes.MultinomialNB(),
               linear_model.LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=9999),
               tree.DecisionTreeClassifier(),
               linear_model.SGDClassifier(loss="log", penalty="l2", max_iter=50),
               MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
               beta_2=0.999, early_stopping=False, epsilon=1e-08,
               hidden_layer_sizes=(20, 20, 20), learning_rate='constant',
               learning_rate_init=0.001, max_iter=500, momentum=0.9,
               nesterovs_momentum=True, power_t=0.5, random_state=None,
               shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
               verbose=False, warm_start=False)]

classifier_names = ['KNN','Multinomial NB','Logistic', 'Decision Tree', 'SGD', 'MLP']
X_valid_scaled_standard_tfidf = scaler.transform(xvalid_tfidf)
accuracies_tfidf_standard = []
f1_tfidf_standard = []
macro_tfidf_standard = []
# iterate through the loop, training and fitting the tweet data
for clf, name in zip(classifiers,classifier_names):
    clf.fit(X_train_standard, ytrain_tfidf)
    prediction = clf.predict_proba(X_valid_scaled_standard_tfidf)
    prediction_int = prediction[:,1] >= 0.3
    prediction_int = prediction_int.astype(np.int)
    acc_tfidf_stan = metrics.accuracy_score(yvalid_tfidf, prediction_int)
    accuracies_tfidf_standard.append(acc_tfidf_stan)
    f1_tfidf_stan = f1_score(yvalid_tfidf, prediction_int, average='weighted')
    f1_tfidf_standard.append(f1_tfidf_stan)
    macro_tfidf_stan = f1_score(yvalid_tfidf, prediction_int, average='macro')
    macro_tfidf_standard.append(macro_tfidf_stan)
# save the accuracies in a DataFrame
models_tfidf_standard = pd.DataFrame({'model':classifier_names, 'standard':accuracies_tfidf_standard})    
#models_tfidf_standard

"""**Accuracy Scores for the Default and Scaled Algorithms**"""

# data frame showing all the scaled and unscaled algorithm results
models_acc = pd.DataFrame({'Model':classifier_names, 
                       'Bag-of-Words':accuracies_bow, 
                       'BoW MaxAbScaled': accuracies_bow_normal, 
                       'BoW Standardised':accuracies_bow_standard, 
                       'TF-IDF':accuracies_tfidf, 
                       'TF-IDF MaxAbScaled':accuracies_tfidf_normal, 
                       'TF-IDF Standardised':accuracies_tfidf_standard})    
models_acc

"""**Weighted F1 Scores for the Default and Scaled Algorithms**"""

# data frame showing all the scaled and unscaled algorithm results
models_f1 = pd.DataFrame({'Model':classifier_names, 
                       'Bag-of-Words':f1_bow, 
                       'BoW MaxAbScaled': f1_bow_normal, 
                       'BoW Standardised':f1_bow_standard, 
                       'TF-IDF':tfidf_f1, 
                       'TF-IDF MaxAbScaled':f1_tfidf_normal, 
                       'TF-IDF Standardised':f1_tfidf_standard})    
models_f1

"""**Macro F1 Scores for the Default and Scaled Algorithms**"""

# data frame showing all the scaled and unscaled algorithm results
models_macro_f1 = pd.DataFrame({'Model':classifier_names, 
                        'Bag-of-Words':macro_bow, 
                        'BoW MaxAbScaled': macro_bow_normal, 
                        'BoW Standardised':macro_bow_standard, 
                        'TF-IDF':tfidf_macro, 
                        'TF-IDF MaxAbScaled':macro_tfidf_normal, 
                        'TF-IDF Standardised':macro_tfidf_standard})    
models_macro_f1

"""**Parameter-Tuning for the TF-IDF Logistic Regression Algorithm**"""

best = 0.0
best_f1 = 0.0
best_macro = 0.0
best_c = 0
best_solver = ''
best_multiclass = ''
# iterate through the parameter variables
for c in range(1,30):
    for solver in ['saga', 'newton-cg','lbfgs','sag']:
        for multiclass in ['ovr', 'multinomial', 'auto']:
                clf = linear_model.LogisticRegression(solver=solver, C=c, multi_class=multiclass, max_iter=9999)
                clf.fit(xtrain_tfidf, ytrain_tfidf)
                # set up the predictions
                prediction = clf.predict_proba(xvalid_tfidf)
                prediction_int = prediction[:,1] >= 0.3
                prediction_int = prediction_int.astype(np.int)
                acc = metrics.accuracy_score(yvalid_tfidf, prediction_int)
                f1 = f1_score(yvalid_tfidf, prediction_int, average='weighted')
                macro = f1_score(yvalid_tfidf, prediction_int, average='macro')
                # find the best parameters for the algorithm 
                if macro > best_macro:
                    best_macro = macro
                    best_c = c
                    best_solver = solver
                    best_multiclass = multiclass
                if acc > best:
                    best = acc
                if f1 > best_f1:
                    best_f1 = f1
print('Best Accuracy was '+str(best)+', the best Macro F1 was '+str(best_macro)+' and the best F1 was '+str(best_f1)+' using '+str(best_c)+' C, the '+str(best_solver)+' solver and using the multi class, '+str(best_multiclass))

"""**Parameter Tuning for the Bag-of-Words Logistic Regression Algorithm**"""

best = 0.0
best_f1 = 0.0
best_macro = 0.0
best_c = 0
best_solver = ''
best_multiclass = ''
# iterate through the parameter variables
for c in range(1,30):
    for solver in ['saga', 'newton-cg','lbfgs','sag']:
        for multiclass in ['ovr', 'multinomial', 'auto']:
                clf = linear_model.LogisticRegression(solver=solver, C=c, multi_class=multiclass, max_iter=9999)
                clf.fit(xtrain_bow, ytrain)
                # set up the predictions
                prediction = clf.predict_proba(xvalid_bow)
                prediction_int = prediction[:,1] >= 0.3
                prediction_int = prediction_int.astype(np.int)
                acc = metrics.accuracy_score(yvalid, prediction_int)
                f1 = f1_score(yvalid, prediction_int, average='weighted')
                macro = f1_score(yvalid, prediction_int, average='macro')
                # find the best parameters for the algorithm 
                if macro > best_macro:
                    best_macro = macro
                    best_c = c
                    best_solver = solver
                    best_multiclass = multiclass
                if acc > best:
                    best = acc
                if f1 > best_f1:
                    best_f1 = f1
print('Best Accuracy was '+str(best)+', the best Macro F1 was '+str(best_macro)+' and the best F1 was '+str(best_f1)+' using '+str(best_c)+' C, the '+str(best_solver)+' solver and using the multi class, '+str(best_multiclass))

"""**Parameter Tuning for the TF-IDF SGD**"""

best = 0.0
best_f1 = 0.0
best_macro = 0.0
best_c = 0
best_solver = ''
best_multiclass = ''
# iterate through the parameter variables
for v in range(1,30):
    for penalty in ['l2', 'l1','elasticnet']:
        for lr in ['optimal']:
                clf = linear_model.SGDClassifier(loss='log', penalty=penalty, verbose=v, learning_rate=lr, max_iter=9999, shuffle=True)
                clf.fit(xtrain_tfidf, ytrain_tfidf)
                # set up the predictions
                prediction = clf.predict_proba(xvalid_tfidf)
                prediction_int = prediction[:,1] >= 0.3
                prediction_int = prediction_int.astype(np.int)
                acc = metrics.accuracy_score(yvalid_tfidf, prediction_int)
                f1 = f1_score(yvalid_tfidf, prediction_int, average='weighted')
                macro = f1_score(yvalid_tfidf, prediction_int, average='macro')
                # find the best parameters for the algorithm 
                if macro > best_macro:
                    best_macro = macro
                    best_v = v
                    best_penalty = penalty
                    best_lr = lr
                if acc > best:
                    best = acc
                if f1 > best_f1:
                    best_f1 = f1
print('Best Accuracy was '+str(best)+', the best Macro F1 was '+str(best_macro)+' and the best F1 was '+str(best_f1)+' using '+str(best_v)+' verbose, the '+str(best_penalty)+' penalty and using the learning rate, '+str(best_lr))

"""**Parameter Tuning for the Bag-of-Words SGD**"""

best = 0.0
best_f1 = 0.0
best_macro = 0.0
best_c = 0
best_solver = ''
best_multiclass = ''
# iterate through the parameter variables
for v in range(1,30):
    for penalty in ['l2', 'l1','elasticnet']:
        for lr in ['optimal']:
                clf = linear_model.SGDClassifier(loss='log', penalty=penalty, verbose=v, learning_rate=lr, max_iter=9999, shuffle=True)
                clf.fit(xtrain_bow, ytrain)
                # set up the predictions
                prediction = clf.predict_proba(xvalid_bow)
                prediction_int = prediction[:,1] >= 0.3
                prediction_int = prediction_int.astype(np.int)
                acc = metrics.accuracy_score(yvalid, prediction_int)
                f1 = f1_score(yvalid, prediction_int, average='weighted')
                macro = f1_score(yvalid, prediction_int, average='macro')
                # find the best parameters for the algorithm 
                if macro > best_macro:
                    best_macro = macro
                    best_v = v
                    best_penalty = penalty
                    best_lr = lr
                if acc > best:
                    best = acc
                if f1 > best_f1:
                    best_f1 = f1
print('Best Accuracy was '+str(best)+', the best Macro F1 was '+str(best_macro)+' and the best F1 was '+str(best_f1)+' using '+str(best_v)+' verbose, the '+str(best_penalty)+' penalty and using the learning rate, '+str(best_lr))

"""**Parameter Tuning for the TF-IDF Logistic Regression Algorithm after MaxAbScaling**"""

# scale the training data with maximum absolute scaling
scalerminmax = preprocessing.MaxAbsScaler()
scalerminmax.fit(xtrain_tfidf)
# transfrom and scale the data
X_train_scaled_minmax_tfidf = scalerminmax.transform(xtrain_tfidf)
X_train_scaled_minmax_tfidf[0]

best = 0.0
best_f1 = 0.0
best_macro = 0.0
best_c = 0
best_solver = ''
best_multiclass = ''
# iterate through the parameter variables
for c in range(1,30):
    for solver in ['saga', 'newton-cg','lbfgs','sag']:
        for multiclass in ['ovr', 'multinomial', 'auto']:
                clf = linear_model.LogisticRegression(solver=solver, C=c, multi_class=multiclass, max_iter=9999)
                clf.fit(X_train_scaled_minmax_tfidf, ytrain_tfidf)
                X_valid_scaled_normal_tfidf = scalerminmax.transform(xvalid_tfidf)
                # set up the predictions
                prediction = clf.predict_proba(X_valid_scaled_normal_tfidf)
                prediction_int = prediction[:,1] >= 0.3
                prediction_int = prediction_int.astype(np.int)
                acc = metrics.accuracy_score(yvalid_tfidf, prediction_int)
                f1 = f1_score(yvalid_tfidf, prediction_int, average='weighted')
                macro = f1_score(yvalid_tfidf, prediction_int, average='macro')
                # find the best parameters for the algorithm 
                if macro > best_macro:
                    best_macro = macro
                    best_c = c
                    best_solver = solver
                    best_multiclass = multiclass
                if acc > best:
                    best = acc
                if f1 > best_f1:
                    best_f1 = f1
print('Best Accuracy was '+str(best)+', the best Macro F1 was '+str(best_macro)+' and the best F1 was '+str(best_f1)+' using '+str(best_c)+' C, the '+str(best_solver)+' solver and using the multi class, '+str(best_multiclass))

"""**Parameter Tuning for the TF-IDF SGD Algorithm after MaxAbScaling**"""

# scale the training data with maximum absolute scaling
scalerminmax = preprocessing.MaxAbsScaler()
scalerminmax.fit(xtrain_tfidf)
# transfrom and scale the data
X_train_scaled_minmax_tfidf = scalerminmax.transform(xtrain_tfidf)
X_train_scaled_minmax_tfidf[0]

best = 0.0
best_f1 = 0.0
best_macro = 0.0
best_c = 0
best_solver = ''
best_multiclass = ''
# iterate through the parameter variables
for v in range(1,30):
    for penalty in ['l2', 'l1','elasticnet']:
        for lr in ['optimal']:
                clf = linear_model.SGDClassifier(loss='log', penalty=penalty, verbose=v, learning_rate=lr, max_iter=9999, shuffle=True)
                clf.fit(X_train_scaled_minmax_tfidf, ytrain_tfidf)
                X_valid_scaled_normal_tfidf = scalerminmax.transform(xvalid_tfidf)
                # set up the predictions
                prediction = clf.predict_proba(X_valid_scaled_normal_tfidf)
                prediction_int = prediction[:,1] >= 0.3
                prediction_int = prediction_int.astype(np.int)
                acc = metrics.accuracy_score(yvalid_tfidf, prediction_int)
                f1 = f1_score(yvalid_tfidf, prediction_int, average='weighted')
                macro = f1_score(yvalid_tfidf, prediction_int, average='macro')
                # find the best parameters for the algorithm 
                if macro > best_macro:
                    best_macro = macro
                    best_v = v
                    best_penalty = penalty
                    best_lr = lr
                if acc > best:
                    best = acc
                if f1 > best_f1:
                    best_f1 = f1
print('Best Accuracy was '+str(best)+', the best Macro F1 was '+str(best_macro)+' and the best F1 was '+str(best_f1)+' using '+str(best_v)+' verbose, the '+str(best_penalty)+' penalty and using the learning rate, '+str(best_lr))

"""**Recurrent Neural Network**"""

import tensorflow as tf
from sklearn.model_selection import train_test_split
# The maximum number of words to be used (most frequent)
MAX_NB_WORDS = 50000
# Max number of words in each complaint
MAX_SEQUENCE_LENGTH = 250
# This is fixed
EMBEDDING_DIM = 100
# tokenise the tweets 
tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_NB_WORDS, filters='!"#$%&()*+,-./:;<=>?@[\]^_`{|}~', lower=True)
tokenizer.fit_on_texts(tweets_df['tweet'].values)
word_index = tokenizer.word_index
print('Found %s unique tokens.' % len(word_index))

# find the sequence for all tweets in the dataset
X = tokenizer.texts_to_sequences(tweets_df['tweet'].values)
X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)
# find the tensor shape
print('Shape of data tensor:', X.shape)

# find the tensor shape for the categories
Y = pd.get_dummies(tweets_df['subtask_c']).values
print('Shape of label tensor:', Y.shape)

# set up a train test split to get the data 
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)
print(X_train.shape,Y_train.shape)
print(X_test.shape,Y_test.shape)

# sets up a method to compute the f1 score 
def get_f1(y_true, y_pred): #taken from old keras source code
    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))
    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))
    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())
    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())
    # f1 score is calculated using the prescision and recall from the predicted positives
    f1_val = 2*(precision*recall)/(precision+recall+tf.keras.backend.epsilon())
    return f1_val

import tensorflow as tf
import keras.backend as K

def f1(y_true, y_pred):
    y_pred = K.round(y_pred)
    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)
    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)
    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)
    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)

    p = tp / (tp + fp + K.epsilon())
    r = tp / (tp + fn + K.epsilon())

    f1 = 2*p*r / (p+r+K.epsilon())
    #f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)
    return K.mean(f1)

"""**LSTM Model**"""

# set up a sequential model for the f1 scores
model_f1 = tf.keras.Sequential()
model_f1.add(tf.keras.layers.Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))
model_f1.add(tf.keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))
model_f1.add(tf.keras.layers.LSTM(64, return_sequences=True))
model_f1.add(tf.keras.layers.Dense(32, activation='relu'))
model_f1.add(tf.keras.layers.LSTM(16, return_sequences=True))
model_f1.add(tf.keras.layers.SpatialDropout1D(0.2))
model_f1.add(tf.keras.layers.Flatten())
model_f1.add(tf.keras.layers.Dense(3, activation='relu'))
# compile the model using the f1 metric
model_f1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1])

# how many iterations and the size of data batches
epochs = 10
batch_size = 64

# train the model using the training data
history = model_f1.fit(X_train, 
                    Y_train, 
                    shuffle=True,
                    epochs=epochs, 
                    batch_size=batch_size,
                    validation_split=0.1)
                    #callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])

model_f1.summary()

"""**GRU Model**"""

# set up a sequential model for the f1 scores
model_f1 = tf.keras.Sequential()
model_f1.add(tf.keras.layers.Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))
model_f1.add(tf.keras.layers.GRU(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))
model_f1.add(tf.keras.layers.GRU(64, return_sequences=True))
model_f1.add(tf.keras.layers.Dense(32, activation='relu'))
model_f1.add(tf.keras.layers.GRU(16, return_sequences=True))
model_f1.add(tf.keras.layers.SpatialDropout1D(0.2))
model_f1.add(tf.keras.layers.Flatten())
model_f1.add(tf.keras.layers.Dense(3, activation='relu'))
# compile the model using the f1 metric
model_f1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1])

# how many iterations and the size of data batches
epochs = 10
batch_size = 64

# train the model using the training data
history = model_f1.fit(X_train, 
                    Y_train, 
                    shuffle=True,
                    epochs=epochs, 
                    batch_size=batch_size,
                    validation_split=0.1)

model_f1.summary()

# find the loss and f1 of the network
f1 = model_f1.evaluate(X_test,Y_test)
print('Test set\n  Loss: {:0.3f}\n  F1 Score: {:0.3f}'.format(f1[0],f1[1]))

# create a line graph to show the training and testing loss
plt.title('Loss')
plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='test')
plt.legend()
plt.show();

# create a line graph to show the training and testing accuracy
plt.title('F1 Score')
plt.plot(history.history['f1'], label='train')
plt.plot(history.history['val_f1'], label='test')
plt.legend()
plt.show();

"""**DistilBert**"""

!pip install transformers==2.10.0

!pip install simpletransformers

from simpletransformers.classification import ClassificationModel
from sklearn.model_selection import train_test_split

tweets_df.drop(['subtask_a', 'subtask_b'], axis = 1, inplace = True, errors = 'ignore')
tweets_df.head()

tweets_df.dropna()

# Create a ClassificationModel
model = ClassificationModel('distilbert', 'distilbert-base-uncased', num_labels=3, use_cuda=False)

tweets_df['tweet'] = tweets_df['tweet'].str.lower()

tweets_df.head()

xtrain, ytrain, xvalid, yvalid = train_test_split(tweets_df, tweets_df['subtask_c'], test_size=0.2)

train_df = pd.DataFrame(xtrain)
eval_df = pd.DataFrame(ytrain)

# Train the model
model.train_model(xtrain)

from sklearn.metrics import f1_score, accuracy_score


def f1_multiclass(labels, preds):
    return f1_score(labels, preds, average='macro')
    
result, model_outputs, wrong_predictions = model.eval_model(eval_df, f1=f1_multiclass, acc=accuracy_score)

result

"""**Flair**"""

!pip install flair

import flair
import torch

data = pd.read_csv("drive/My Drive/OLIDv1.0/olid-training-v1.0.tsv", encoding='latin-1', error_bad_lines=False).sample(frac=1).drop_duplicates()
 
data = tweets_df[['tweet', 'subtask_c']].rename(columns={"tweet":"text", "subtask_c":"labels"})
 
data['labels'] = '__labels__' + data['labels'].astype(str)
 
data.iloc[0:int(len(data)*0.8)].to_csv('train.csv', sep='\t', index = False, header = False)
data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv('test.csv', sep='\t', index = False, header = False)
data.iloc[int(len(data)*0.9):].to_csv('dev.csv', sep='\t', index = False, header = False);

from flair.data import Corpus
from flair.datasets import CSVClassificationCorpus

data_folder = ''
column_name_map = {0: "text", 1: "labels"}

corpus: Corpus = CSVClassificationCorpus(data_folder,
                                         column_name_map,
                                         skip_header=False,
                                         delimiter='\t') 
label_dict = corpus.make_label_dictionary()
len(corpus.dev)

from flair.data import Corpus
from flair.datasets import TREC_6
from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings
from flair.models import TextClassifier
from flair.trainers import ModelTrainer


# 1. get the corpus
#corpus: Corpus = TREC_6()

# 2. create the label dictionary
label_dict = corpus.make_label_dictionary()

# 3. make a list of word embeddings
word_embeddings = [WordEmbeddings('glove')]

# 4. initialize document embedding by passing list of word embeddings
# Can choose between many RNN types (GRU by default, to change use rnn_type parameter)
document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=256)

# 5. create the text classifier
classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)

# 6. initialize the text classifier trainer
trainer = ModelTrainer(classifier, corpus)

# 7. start the training
trainer.train('resources/taggers/trec',
              learning_rate=0.1,
              mini_batch_size=32,
              anneal_factor=0.5,
              patience=5,
              max_epochs=10)
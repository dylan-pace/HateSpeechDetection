# -*- coding: utf-8 -*-
"""SubtaskB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k7lx0-YWk01a_4-lKGb-9cgeue9xnWdM

# **Subtask B**
"""

# Commented out IPython magic to ensure Python compatibility.
import spacy
import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
sns.set()
from sklearn import preprocessing, linear_model, model_selection, neighbors, svm, naive_bayes, metrics, tree
from spacy import displacy
from spacy.tokenizer import Tokenizer
from spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex
import re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from sklearn.preprocessing import LabelEncoder

# instantiates the spacy language module
nlp = spacy.load("en_core_web_sm")

# call and display the dataframe
tweets_df = pd.read_csv('drive/My Drive/OLIDv1.0/olid-training-v1.0.tsv', delimiter="\t")
tweets_df.head()

# size of the dataset
len(tweets_df)

# changes the dataframe index to the tweet id
tweets_df = tweets_df.set_index('id')

# display information about the dataframe
tweets_df.info()

# storing dtype before operation 
dtype_before = type(tweets_df["tweet"]) 
  
# converting to list 
tweet_list = tweets_df["tweet"].tolist() 
  
# storing dtype after operation 
dtype_after = type(tweet_list) 

# stores the tweets in a list
doc = nlp(tweet_list[0])

# shows the first tweet in the list
doc

# shows the tweet split up into indivdual sections
[token.text for token in doc]

"""**Pre-Processing the Dataset**"""

tweets_df.drop(['subtask_a', 'subtask_c'], axis = 1, inplace = True, errors = 'ignore')
tweets_df.head()

tweets_df = tweets_df.dropna()

tweets_df.head()

le = LabelEncoder()
tweets_df['subtask_b'] = le.fit_transform(tweets_df['subtask_b']) 
tweets_df.head()

# method that will remove @USER tags from the data
def remove_pattern(input_txt, pattern):
  r = re.findall(pattern, input_txt)
  for i in r:
    input_txt = re.sub(i, '', input_txt)

  return input_txt

# tags are removed and a new dataset without them is saved
tweets_df['tweet'] = np.vectorize(remove_pattern)(tweets_df['tweet'], "@[\w]*")

# URL links had been changes to 'URL' so they have been removed as they're unnecessary
tweets_df['tweet'] = np.vectorize(remove_pattern)(tweets_df['tweet'], "URL")

# removes useless emoticons and punctuation
tweets_df['tweet'] = tweets_df['tweet'].str.replace("[^a-zA-Z#']", " " )

# displays the processed data without tags, URL or useless punctuation
tweets_df.head()

barData = pd.read_csv('drive/My Drive/OLIDv1.0/olid-training-v1.0.tsv', delimiter="\t")
sns.countplot(x = 'subtask_b',  data = barData, palette = 'magma')
plt.ylabel('Number of Tweets')
plt.xlabel('Tweet Classification')
plt.title('The Amount of Targeted and Non-Targeted Tweets')
plt.show()

"""**Machine Learning using the Bag-of-Words Method**"""

from sklearn.feature_extraction.text import CountVectorizer
# create a count vector to extract the words as bag-of-words
bow_vect = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')
# transform the tweets into the vectorisation
bow = bow_vect.fit_transform(tweets_df['tweet'])

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import f1_score

# create the training and testing bag-of-words
train_bow = bow[:13240, :] #31962
test_bow = bow[13240:, :]

# set up a training and testing split 
xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(train_bow, tweets_df['subtask_b'], random_state=42, test_size=0.2)

# instantiate the logistic regression function
lreg = LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=9999)
lreg.fit(xtrain_bow, ytrain)

# set up the predictions
prediction = lreg.predict_proba(xvalid_bow)
prediction_int = prediction[:,1] >= 0.3
prediction_int = prediction_int.astype(np.int)

# calculate the baseline accuracy
baseline_predictions = [1 for x in yvalid]
metrics.accuracy_score(yvalid, baseline_predictions)

# display the logistic regression f1 prediction
f1_score(yvalid, prediction_int)

# prediction accuracy
metrics.accuracy_score(yvalid, prediction_int)

# set up a heatmap to visualise the predictions of the logistic regression algorithm
cm = metrics.confusion_matrix(yvalid, prediction_int, labels = [0, 1])
fig, ax = plt.subplots()
sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm',cbar=False, ax=ax)
ax.set_xticklabels(['Targeted','Untrageted'])
ax.set_yticklabels(['Targeted','Untargeted'])
ax.set_xlabel('Predicted Class')
ax.set_title('Heatmap Showing the Predictions for the Logistic Regression Algorithm using Bag-of-Words.')
# I had to offset the ylim because matplotlib's newest update has caused them to go wonky otherwise
ax.set_ylim([0,2])
ax.set_ylabel('True Class');

# instantiate some machine learning functions
classifiers = [neighbors.KNeighborsClassifier(),
               naive_bayes.MultinomialNB(),
               linear_model.LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=9999),
               tree.DecisionTreeClassifier(),
               linear_model.SGDClassifier(loss="log", penalty="l2", max_iter=50),
               MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
               beta_2=0.999, early_stopping=False, epsilon=1e-08,
               hidden_layer_sizes=(20, 20, 20), learning_rate='constant',
               learning_rate_init=0.001, max_iter=500, momentum=0.9,
               nesterovs_momentum=True, power_t=0.5, random_state=None,
               shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
               verbose=False, warm_start=False)]

classifier_names = ['KNN','Multinomial NB','Logistic', 'Decision Tree', 'SGD', 'MLP']
accuracies_bow = []
f1_bow = []
macro_bow = []
# iterate through the loop, training and fitting the tweet data
for clf, name in zip(classifiers,classifier_names):
    clf.fit(xtrain_bow, ytrain)
    prediction = clf.predict_proba(xvalid_bow)
    prediction_int = prediction[:,1] >= 0.3
    prediction_int = prediction_int.astype(np.int)
    acc = metrics.accuracy_score(yvalid, prediction_int)
    accuracies_bow.append(acc)
    f1 = f1_score(yvalid, prediction_int)
    f1_bow.append(f1)
    macro = f1_score(yvalid, prediction_int, average='macro')
    macro_bow.append(macro)
# save the accuracies in a DataFrame
models_bow = pd.DataFrame({'Model':classifier_names, 'Accuracy Baseline':accuracies_bow})

# save the f1 scores to a dataframe
models_bow_f1 = pd.DataFrame({'Model':classifier_names, 'F1 Baseline':f1_bow})

"""**Machine Learning using the TF-IDF Method**"""

from sklearn.feature_extraction.text import TfidfVectorizer
# create a count vector to extract the words as TF-IDF
tfidf_vect = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')
# transform the tweets into the vectorisation
tfidf = tfidf_vect.fit_transform(tweets_df['tweet'])

# create the training and testing tfidf sets
train_tfidf = tfidf[:13240, :] #31962
test_tfidf = tfidf[13240:, :]

# set up a training and testing split 
xtrain_tfidf, xvalid_tfidf, ytrain_tfidf, yvalid_tfidf = train_test_split(train_tfidf, tweets_df['subtask_b'], random_state=42, test_size=0.2)

# instantiate the logistic regression function
lreg = linear_model.SGDClassifier(loss="log", penalty="l2", max_iter=50)#LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=9999)
lreg.fit(xtrain_tfidf, ytrain_tfidf)

# set up the predictions
prediction = lreg.predict_proba(xvalid_tfidf)
prediction_int = prediction[:,1] >= 0.3
prediction_int = prediction_int.astype(np.int)

# display the model accuracy
metrics.accuracy_score(yvalid_tfidf, prediction_int)

# display the logistic regression f1 prediction
f1_score(yvalid_tfidf, prediction_int)

# set up a heatmap to visualise the predictions of the logistic regression algorithm
cm = metrics.confusion_matrix(yvalid_tfidf, prediction_int, labels = [0, 1])
fig, ax = plt.subplots()
sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm',cbar=False, ax=ax)
ax.set_xticklabels(['Targeted','Untargeted'])
ax.set_yticklabels(['Targeted','Untargeted'])
ax.set_xlabel('Predicted Class')
ax.set_title('Heatmap Showing the Predictions for the SGD Algorithm using TF-IDF.')
# I had to offset the ylim because matplotlib's newest update has caused them to go wonky otherwise
ax.set_ylim([0,2])
ax.set_ylabel('True Class');

# instantiate some machine learning functions
classifiers = [neighbors.KNeighborsClassifier(),
               naive_bayes.MultinomialNB(),
               linear_model.LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=9999),
               tree.DecisionTreeClassifier(),
               linear_model.SGDClassifier(loss="log", penalty="l2", max_iter=50),
               MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
               beta_2=0.999, early_stopping=False, epsilon=1e-08,
               hidden_layer_sizes=(20, 20, 20), learning_rate='constant',
               learning_rate_init=0.001, max_iter=500, momentum=0.9,
               nesterovs_momentum=True, power_t=0.5, random_state=None,
               shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
               verbose=False, warm_start=False)]

classifier_names = ['KNN','Multinomial NB','Logistic', 'Decision Tree', 'SGD', 'MLP']
accuracies_tfidf = []
tfidf_f1 = []
tfidf_macro = []
# iterate through the loop, training and fitting the tweet data
for clf, name in zip(classifiers,classifier_names):
    clf.fit(xtrain_tfidf, ytrain_tfidf)
    prediction = clf.predict_proba(xvalid_tfidf)
    prediction_int = prediction[:,1] >= 0.3
    prediction_int = prediction_int.astype(np.int)
    acc = metrics.accuracy_score(yvalid_tfidf, prediction_int)
    accuracies_tfidf.append(acc)
    f1 = f1_score(yvalid_tfidf, prediction_int)
    tfidf_f1.append(f1)
    macro = f1_score(yvalid_tfidf, prediction_int, average='macro')
    tfidf_macro.append(macro)
# save the accuracies in a DataFrame
models_tfidf = pd.DataFrame({'Model':classifier_names, 'Accuracy Baseline':accuracies_tfidf})

# f1 scores
models_tfidf = pd.DataFrame({'Model':classifier_names, 'F1 Baseline':tfidf_f1})

# accuracies of the algorithms for the two methods
models = pd.DataFrame({'Model':classifier_names, 'Bag-of-Words Accuracy':accuracies_bow, 'TF-IDF Accuracy':accuracies_tfidf})

models_all = pd.DataFrame({'Model':classifier_names, 'BoW Accuracy': accuracies_bow, 'TF-IDF Accuracy': accuracies_tfidf, 'BoW F1':f1_bow, 'TF-IDF F1':tfidf_f1, 'BoW Macro F1':macro_bow, 'TF-IDF Macro F1':tfidf_macro})

# comparison between the f1 scores and accuracies of all algorithms between the two methods
models_all

"""**Maximum Absolute Scaling of the Bag-of-Words Data**"""

scalerminmax = preprocessing.MaxAbsScaler()
scalerminmax.fit(xtrain_bow)
X_train_scaled_minmax_bow = scalerminmax.transform(xtrain_bow)
X_train_scaled_minmax_bow[0]

# instantiate some machine learning functions
classifiers = [neighbors.KNeighborsClassifier(),
               naive_bayes.MultinomialNB(),
               linear_model.LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=9999),
               tree.DecisionTreeClassifier(),
               linear_model.SGDClassifier(loss="log", penalty="l2", max_iter=50),
               MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
               beta_2=0.999, early_stopping=False, epsilon=1e-08,
               hidden_layer_sizes=(20, 20, 20), learning_rate='constant',
               learning_rate_init=0.001, max_iter=500, momentum=0.9,
               nesterovs_momentum=True, power_t=0.5, random_state=None,
               shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
               verbose=False, warm_start=False)]

classifier_names = ['KNN','Multinomial NB','Logistic', 'Decision Tree', 'SGD', 'MLP']
X_valid_scaled_normal_bow = scalerminmax.transform(xvalid_bow)
accuracies_bow_normal = []
f1_bow_normal = []
macro_bow_normal = []
# iterate through the loop, training and fitting the tweet data
for clf, name in zip(classifiers,classifier_names):
    clf.fit(X_train_scaled_minmax_bow, ytrain)
    prediction = clf.predict_proba(X_valid_scaled_normal_bow)
    prediction_int = prediction[:,1] >= 0.3
    prediction_int = prediction_int.astype(np.int)
    acc_bow_max = metrics.accuracy_score(yvalid, prediction_int)
    accuracies_bow_normal.append(acc_bow_max)
    f1_bow_max = f1_score(yvalid, prediction_int)
    f1_bow_normal.append(f1_bow_max)
    macro_bow_norm = f1_score(yvalid, prediction_int, average='macro')
    macro_bow_normal.append(macro_bow_norm)
# save the accuracies in a DataFrame
models_bow_normal = pd.DataFrame({'model':classifier_names, 'MaxAbScaled':accuracies_bow_normal})    
#models_bow_normal

"""**Standardisation of the Bag-of-Words Data**"""

# scale the data using standardisation
scaler = preprocessing.StandardScaler(with_mean=False)
scaler.fit(xtrain_bow)
# transform and scale the data
X_train_standard_bow = scaler.transform(xtrain_bow)
X_train_standard_bow[0]

# instantiate some machine learning functions
classifiers = [neighbors.KNeighborsClassifier(),
               naive_bayes.MultinomialNB(),
               linear_model.LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=9999),
               tree.DecisionTreeClassifier(),
               linear_model.SGDClassifier(loss="log", penalty="l2", max_iter=50),
               MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
               beta_2=0.999, early_stopping=False, epsilon=1e-08,
               hidden_layer_sizes=(20, 20, 20), learning_rate='constant',
               learning_rate_init=0.001, max_iter=500, momentum=0.9,
               nesterovs_momentum=True, power_t=0.5, random_state=None,
               shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
               verbose=False, warm_start=False)]

classifier_names = ['KNN','Multinomial NB','Logistic', 'Decision Tree', 'SGD', 'MLP']
X_valid_scaled_standard_bow = scaler.transform(xvalid_bow)
accuracies_bow_standard = []
f1_bow_standard = []
macro_bow_standard = []
# iterate through the loop, training and fitting the tweet data
for clf, name in zip(classifiers,classifier_names):
    clf.fit(X_train_standard_bow, ytrain)
    prediction = clf.predict_proba(X_valid_scaled_standard_bow)
    prediction_int = prediction[:,1] >= 0.3
    prediction_int = prediction_int.astype(np.int)
    acc_bow_stan = metrics.accuracy_score(yvalid, prediction_int)
    accuracies_bow_standard.append(acc_bow_stan)
    f1_bow_stan = f1_score(yvalid, prediction_int)
    f1_bow_standard.append(f1_bow_stan)
    macro_bow_stan = f1_score(yvalid, prediction_int, average='macro')
    macro_bow_standard.append(macro_bow_stan)
# save the accuracies in a DataFrame
models_tfidf_bow = pd.DataFrame({'model':classifier_names, 'standard':accuracies_bow_standard})    
#models_tfidf_bow

"""**Maximum Absolute Scaling of the TF-IDF Data**"""

# scale the training data with maximum absolute scaling
scalerminmax = preprocessing.MaxAbsScaler()
scalerminmax.fit(xtrain_tfidf)
# transfrom and scale the data
X_train_scaled_minmax_tfidf = scalerminmax.transform(xtrain_tfidf)
X_train_scaled_minmax_tfidf[0]

# instantiate some machine learning functions
classifiers = [neighbors.KNeighborsClassifier(),
               naive_bayes.MultinomialNB(),
               linear_model.LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=9999),
               tree.DecisionTreeClassifier(),
               linear_model.SGDClassifier(loss="log", penalty="l2", max_iter=50),
               MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
               beta_2=0.999, early_stopping=False, epsilon=1e-08,
               hidden_layer_sizes=(20, 20, 20), learning_rate='constant',
               learning_rate_init=0.001, max_iter=500, momentum=0.9,
               nesterovs_momentum=True, power_t=0.5, random_state=None,
               shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
               verbose=False, warm_start=False)]

classifier_names = ['KNN','Multinomial NB','Logistic', 'Decision Tree', 'SGD', 'MLP']
X_valid_scaled_normal_tfidf = scalerminmax.transform(xvalid_tfidf)
accuracies_tfidf_normal = []
f1_tfidf_normal = []
macro_tfidf_normal = []
# iterate through the loop, training and fitting the tweet data
for clf, name in zip(classifiers,classifier_names):
    clf.fit(X_train_scaled_minmax_tfidf, ytrain_tfidf)
    # find the results
    prediction = clf.predict_proba(X_valid_scaled_normal_tfidf)
    prediction_int = prediction[:,1] >= 0.3
    prediction_int = prediction_int.astype(np.int)
    acc_tfidf_max = metrics.accuracy_score(yvalid_tfidf, prediction_int)
    accuracies_tfidf_normal.append(acc_tfidf_max)
    f1_tfidf_max = f1_score(yvalid_tfidf, prediction_int)
    f1_tfidf_normal.append(f1_tfidf_max)
    macro_tfidf_norm = f1_score(yvalid_tfidf, prediction_int, average='macro')
    macro_tfidf_normal.append(macro_tfidf_norm)
# save the accuracies in a DataFrame
models_tfidf_normal = pd.DataFrame({'model':classifier_names, 'MaxAbScaled':accuracies_tfidf_normal})    
#models_tfidf_normal

"""**Standardisation of the TF-IDF Data**"""

scaler = preprocessing.StandardScaler(with_mean=False)
scaler.fit(xtrain_tfidf)
X_train_standard = scaler.transform(xtrain_tfidf)
X_train_standard[0]

# instantiate some machine learning functions
classifiers = [neighbors.KNeighborsClassifier(),
               naive_bayes.MultinomialNB(),
               linear_model.LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=9999),
               tree.DecisionTreeClassifier(),
               linear_model.SGDClassifier(loss="log", penalty="l2", max_iter=50),
               MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
               beta_2=0.999, early_stopping=False, epsilon=1e-08,
               hidden_layer_sizes=(20, 20, 20), learning_rate='constant',
               learning_rate_init=0.001, max_iter=500, momentum=0.9,
               nesterovs_momentum=True, power_t=0.5, random_state=None,
               shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
               verbose=False, warm_start=False)]

classifier_names = ['KNN','Multinomial NB','Logistic', 'Decision Tree', 'SGD', 'MLP']
X_valid_scaled_standard_tfidf = scaler.transform(xvalid_tfidf)
accuracies_tfidf_standard = []
f1_tfidf_standard = []
macro_tfidf_standard = []
# iterate through the loop, training and fitting the tweet data
for clf, name in zip(classifiers,classifier_names):
    clf.fit(X_train_standard, ytrain_tfidf)
    prediction = clf.predict_proba(X_valid_scaled_standard_tfidf)
    prediction_int = prediction[:,1] >= 0.3
    prediction_int = prediction_int.astype(np.int)
    acc_tfidf_stan = metrics.accuracy_score(yvalid_tfidf, prediction_int)
    accuracies_tfidf_standard.append(acc_tfidf_stan)
    f1_tfidf_stan = f1_score(yvalid_tfidf, prediction_int)
    f1_tfidf_standard.append(f1_tfidf_stan)
    macro_tfidf_stan = f1_score(yvalid_tfidf, prediction_int, average='macro')
    macro_tfidf_standard.append(macro_tfidf_stan)
# save the accuracies in a DataFrame
models_tfidf_standard = pd.DataFrame({'model':classifier_names, 'standard':accuracies_tfidf_standard})    
#models_tfidf_standard

"""**Accuracy Scores for the Default and Scaled Algorithms**"""

# data frame showing all the scaled and unscaled algorithm results
models_acc = pd.DataFrame({'Model':classifier_names, 
                       'Bag-of-Words':accuracies_bow, 
                       'BoW MaxAbScaled': accuracies_bow_normal, 
                       'BoW Standardised':accuracies_bow_standard, 
                       'TF-IDF':accuracies_tfidf, 
                       'TF-IDF MaxAbScaled':accuracies_tfidf_normal, 
                       'TF-IDF Standardised':accuracies_tfidf_standard})    
models_acc

"""**F1 Scores for the Default and Scaled Algorithms**"""

# data frame showing all the scaled and unscaled algorithm results
models_f1 = pd.DataFrame({'Model':classifier_names, 
                       'Bag-of-Words':f1_bow, 
                       'BoW MaxAbScaled': f1_bow_normal, 
                       'BoW Standardised':f1_bow_standard, 
                       'TF-IDF':tfidf_f1, 
                       'TF-IDF MaxAbScaled':f1_tfidf_normal, 
                       'TF-IDF Standardised':f1_tfidf_standard})    
models_f1

"""**Macro F1 Scores for the Default and Scaled Algorithms**"""

# data frame showing all the scaled and unscaled algorithm results
models_macro_f1 = pd.DataFrame({'Model':classifier_names, 
                        'Bag-of-Words':macro_bow, 
                        'BoW MaxAbScaled': macro_bow_normal, 
                        'BoW Standardised':macro_bow_standard, 
                        'TF-IDF':tfidf_macro, 
                        'TF-IDF MaxAbScaled':macro_tfidf_normal, 
                        'TF-IDF Standardised':macro_tfidf_standard})    
models_macro_f1

"""**Parameter-Tuning for the TF-IDF Logistic Regression Algorithm**"""

best = 0.0
best_f1 = 0.0
best_macro = 0.0
best_c = 0
best_solver = ''
best_multiclass = ''
# iterate through the parameter variables
for c in range(1,30):
    for solver in ['saga', 'newton-cg','lbfgs','sag']:
        for multiclass in ['ovr', 'multinomial', 'auto']:
                clf = linear_model.LogisticRegression(solver=solver, C=c, multi_class=multiclass, max_iter=9999)
                clf.fit(xtrain_tfidf, ytrain_tfidf)
                # set up the predictions
                prediction = clf.predict_proba(xvalid_tfidf)
                prediction_int = prediction[:,1] >= 0.3
                prediction_int = prediction_int.astype(np.int)
                acc = metrics.accuracy_score(yvalid_tfidf, prediction_int)
                f1 = f1_score(yvalid_tfidf, prediction_int)
                macro = f1_score(yvalid_tfidf, prediction_int, average='macro')
                # find the best parameters for the algorithm 
                if macro > best_macro:
                    best_macro = macro
                    best_c = c
                    best_solver = solver
                    best_multiclass = multiclass
                if acc > best:
                    best = acc
                if f1 > best_f1:
                    best_f1 = f1
print('Best Accuracy was '+str(best)+', the best Macro F1 was '+str(best_macro)+' and the best F1 was '+str(best_f1)+' using '+str(best_c)+' C, the '+str(best_solver)+' solver and using the multi class, '+str(best_multiclass))

"""**Parameter Tuning for the Bag-of-Words Logistic Regression Algorithm**"""

best = 0.0
best_f1 = 0.0
best_macro = 0.0
best_c = 0
best_solver = ''
best_multiclass = ''
# iterate through the parameter variables
for c in range(1,30):
    for solver in ['saga', 'newton-cg','lbfgs','sag']:
        for multiclass in ['ovr', 'multinomial', 'auto']:
                clf = linear_model.LogisticRegression(solver=solver, C=c, multi_class=multiclass, max_iter=9999)
                clf.fit(xtrain_bow, ytrain)
                # set up the predictions
                prediction = clf.predict_proba(xvalid_bow)
                prediction_int = prediction[:,1] >= 0.3
                prediction_int = prediction_int.astype(np.int)
                acc = metrics.accuracy_score(yvalid, prediction_int)
                f1 = f1_score(yvalid, prediction_int)
                macro = f1_score(yvalid, prediction_int, average='macro')
                # find the best parameters for the algorithm 
                if macro > best_macro:
                    best_macro = macro
                    best_c = c
                    best_solver = solver
                    best_multiclass = multiclass
                if acc > best:
                    best = acc
                if f1 > best_f1:
                    best_f1 = f1
print('Best Accuracy was '+str(best)+', the best Macro F1 was '+str(best_macro)+' and the best F1 was '+str(best_f1)+' using '+str(best_c)+' C, the '+str(best_solver)+' solver and using the multi class, '+str(best_multiclass))

"""**Parameter Tuning for the TF-IDF SGD**"""

best = 0.0
best_f1 = 0.0
best_macro = 0.0
best_c = 0
best_solver = ''
best_multiclass = ''
# iterate through the parameter variables
for v in range(1,30):
    for penalty in ['l2', 'l1','elasticnet']:
        for lr in ['optimal']:
                clf = linear_model.SGDClassifier(loss='log', penalty=penalty, verbose=v, learning_rate=lr, max_iter=9999, shuffle=True)
                clf.fit(xtrain_tfidf, ytrain_tfidf)
                # set up the predictions
                prediction = clf.predict_proba(xvalid_tfidf)
                prediction_int = prediction[:,1] >= 0.3
                prediction_int = prediction_int.astype(np.int)
                acc = metrics.accuracy_score(yvalid_tfidf, prediction_int)
                f1 = f1_score(yvalid_tfidf, prediction_int)
                macro = f1_score(yvalid_tfidf, prediction_int, average='macro')
                # find the best parameters for the algorithm 
                if macro > best_macro:
                    best_macro = macro
                    best_v = v
                    best_penalty = penalty
                    best_lr = lr
                if acc > best:
                    best = acc
                if f1 > best_f1:
                    best_f1 = f1
print('Best Accuracy was '+str(best)+', the best Macro F1 was '+str(best_macro)+' and the best F1 was '+str(best_f1)+' using '+str(best_v)+' verbose, the '+str(best_penalty)+' penalty and using the learning rate, '+str(best_lr))

# set up a heatmap to visualise the predictions of the parameter-tuned SGD algorithm
cm = metrics.confusion_matrix(yvalid_tfidf, prediction_int, labels = [0, 1])
fig, ax = plt.subplots()
sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm',cbar=False, ax=ax)
ax.set_xticklabels(['Offensive','Non-Offensive'])
ax.set_yticklabels(['Offensive','Non-Offensive'])
ax.set_xlabel('Predicted Class')
ax.set_title('Heatmap Showing the Predictions for the parameter-tuned SGD Algorithm using TF-IDF.')
# I had to offset the ylim because matplotlib's newest update has caused them to go wonky otherwise
ax.set_ylim([0,2])
ax.set_ylabel('True Class');

"""**Parameter Tuning for the Bag-of-Words SGD**"""

best = 0.0
best_f1 = 0.0
best_macro = 0.0
best_c = 0
best_solver = ''
best_multiclass = ''
# iterate through the parameter variables
for v in range(1,30):
    for penalty in ['l2', 'l1','elasticnet']:
        for lr in ['optimal']:
                clf = linear_model.SGDClassifier(loss='log', penalty=penalty, verbose=v, learning_rate=lr, max_iter=9999, shuffle=True)
                clf.fit(xtrain_bow, ytrain)
                # set up the predictions
                prediction = clf.predict_proba(xvalid_bow)
                prediction_int = prediction[:,1] >= 0.3
                prediction_int = prediction_int.astype(np.int)
                acc = metrics.accuracy_score(yvalid, prediction_int)
                f1 = f1_score(yvalid, prediction_int)
                macro = f1_score(yvalid, prediction_int, average='macro')
                # find the best parameters for the algorithm 
                if macro > best_macro:
                    best_macro = macro
                    best_v = v
                    best_penalty = penalty
                    best_lr = lr
                if acc > best:
                    best = acc
                if f1 > best_f1:
                    best_f1 = f1
print('Best Accuracy was '+str(best)+', the best Macro F1 was '+str(best_macro)+' and the best F1 was '+str(best_f1)+' using '+str(best_v)+' verbose, the '+str(best_penalty)+' penalty and using the learning rate, '+str(best_lr))

# set up a heatmap to visualise the predictions of the parameter-tuned SGD algorithm
cm = metrics.confusion_matrix(yvalid, prediction_int, labels = [0, 1])
fig, ax = plt.subplots()
sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm',cbar=False, ax=ax)
ax.set_xticklabels(['Offensive','Non-Offensive'])
ax.set_yticklabels(['Offensive','Non-Offensive'])
ax.set_xlabel('Predicted Class')
ax.set_title('Heatmap Showing the Predictions for the parameter-tuned SGD Algorithm using Bag-of-Words.')
# I had to offset the ylim because matplotlib's newest update has caused them to go wonky otherwise
ax.set_ylim([0,2])
ax.set_ylabel('True Class');

"""**Parameter Tuning for the TF-IDF Logistic Regression Algorithm after MaxAbScaling**"""

# scale the training data with maximum absolute scaling
scalerminmax = preprocessing.MaxAbsScaler()
scalerminmax.fit(xtrain_tfidf)
# transfrom and scale the data
X_train_scaled_minmax_tfidf = scalerminmax.transform(xtrain_tfidf)
X_train_scaled_minmax_tfidf[0]

best = 0.0
best_f1 = 0.0
best_macro = 0.0
best_c = 0
best_solver = ''
best_multiclass = ''
# iterate through the parameter variables
for c in range(1,30):
    for solver in ['saga', 'newton-cg','lbfgs','sag']:
        for multiclass in ['ovr', 'multinomial', 'auto']:
                clf = linear_model.LogisticRegression(solver=solver, C=c, multi_class=multiclass, max_iter=9999)
                clf.fit(X_train_scaled_minmax_tfidf, ytrain_tfidf)
                X_valid_scaled_normal_tfidf = scalerminmax.transform(xvalid_tfidf)
                # set up the predictions
                prediction = clf.predict_proba(X_valid_scaled_normal_tfidf)
                prediction_int = prediction[:,1] >= 0.3
                prediction_int = prediction_int.astype(np.int)
                acc = metrics.accuracy_score(yvalid_tfidf, prediction_int)
                f1 = f1_score(yvalid_tfidf, prediction_int)
                macro = f1_score(yvalid_tfidf, prediction_int, average='macro')
                # find the best parameters for the algorithm 
                if macro > best_macro:
                    best_macro = macro
                    best_c = c
                    best_solver = solver
                    best_multiclass = multiclass
                if acc > best:
                    best = acc
                if f1 > best_f1:
                    best_f1 = f1
print('Best Accuracy was '+str(best)+', the best Macro F1 was '+str(best_macro)+' and the best F1 was '+str(best_f1)+' using '+str(best_c)+' C, the '+str(best_solver)+' solver and using the multi class, '+str(best_multiclass))

"""**Parameter Tuning for the TF-IDF SGD Algorithm after MaxAbScaling**"""

# scale the training data with maximum absolute scaling
scalerminmax = preprocessing.MaxAbsScaler()
scalerminmax.fit(xtrain_tfidf)
# transfrom and scale the data
X_train_scaled_minmax_tfidf = scalerminmax.transform(xtrain_tfidf)
X_train_scaled_minmax_tfidf[0]

best = 0.0
best_f1 = 0.0
best_macro = 0.0
best_c = 0
best_solver = ''
best_multiclass = ''
# iterate through the parameter variables
for v in range(1,30):
    for penalty in ['l2', 'l1','elasticnet']:
        for lr in ['optimal']:
                clf = linear_model.SGDClassifier(loss='log', penalty=penalty, verbose=v, learning_rate=lr, max_iter=9999, shuffle=True)
                clf.fit(X_train_scaled_minmax_tfidf, ytrain_tfidf)
                X_valid_scaled_normal_tfidf = scalerminmax.transform(xvalid_tfidf)
                # set up the predictions
                prediction = clf.predict_proba(X_valid_scaled_normal_tfidf)
                prediction_int = prediction[:,1] >= 0.3
                prediction_int = prediction_int.astype(np.int)
                acc = metrics.accuracy_score(yvalid_tfidf, prediction_int)
                f1 = f1_score(yvalid_tfidf, prediction_int)
                macro = f1_score(yvalid_tfidf, prediction_int, average='macro')
                # find the best parameters for the algorithm 
                if macro > best_macro:
                    best_macro = macro
                    best_v = v
                    best_penalty = penalty
                    best_lr = lr
                if acc > best:
                    best = acc
                if f1 > best_f1:
                    best_f1 = f1
print('Best Accuracy was '+str(best)+', the best Macro F1 was '+str(best_macro)+' and the best F1 was '+str(best_f1)+' using '+str(best_v)+' verbose, the '+str(best_penalty)+' penalty and using the learning rate, '+str(best_lr))

"""**Recurrent Neural Network**"""

import tensorflow as tf
# The maximum number of words to be used (most frequent)
MAX_NB_WORDS = 50000
# Max number of words in each complaint
MAX_SEQUENCE_LENGTH = 250
# This is fixed
EMBEDDING_DIM = 100
# tokenise the tweets 
tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_NB_WORDS, filters='!"#$%&()*+,-./:;<=>?@[\]^_`{|}~', lower=True)
tokenizer.fit_on_texts(tweets_df['tweet'].values)
word_index = tokenizer.word_index
print('Found %s unique tokens.' % len(word_index))

# find the sequence for all tweets in the dataset
X = tokenizer.texts_to_sequences(tweets_df['tweet'].values)
X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)
# find the tensor shape
print('Shape of data tensor:', X.shape)

# find the tensor shape for the categories
Y = pd.get_dummies(tweets_df['subtask_b']).values
print('Shape of label tensor:', Y.shape)

# set up a train test split to get the data 
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)
print(X_train.shape,Y_train.shape)
print(X_test.shape,Y_test.shape)

# sets up a method to compute the f1 score 
def get_f1(y_true, y_pred): #taken from old keras source code
    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))
    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))
    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())
    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())
    # f1 score is calculated using the prescision and recall from the predicted positives
    f1_val = 2*(precision*recall)/(precision+recall+tf.keras.backend.epsilon())
    return f1_val

import tensorflow as tf
import keras.backend as K

def f1(y_true, y_pred):
    y_pred = K.round(y_pred)
    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)
    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)
    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)
    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)

    p = tp / (tp + fp + K.epsilon())
    r = tp / (tp + fn + K.epsilon())

    f1 = 2*p*r / (p+r+K.epsilon())
    #f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)
    return K.mean(f1)

"""**LSTM Default (F1 Score)**"""

# set up a sequential model for the f1 scores
model_f1 = tf.keras.Sequential()
model_f1.add(tf.keras.layers.Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))
model_f1.add(tf.keras.layers.SpatialDropout1D(0.2))
model_f1.add(tf.keras.layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2))
#model_f1.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)))
#model_f1.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)))
model_f1.add(tf.keras.layers.Dense(2, activation='softmax'))
# compile the model using the f1 metric
model_f1.compile(loss='binary_crossentropy', optimizer='adam', metrics=[f1])

# how many iterations and the size of data batches
epochs = 10
batch_size = 64

# train the model using the training data
history = model_f1.fit(X_train, 
                    Y_train, 
                    epochs=epochs,
                    shuffle=True, 
                    batch_size=batch_size,
                    validation_split=0.2)
                    #callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])

model_f1.summary()

# find the loss and f1 of the network
f1 = model_f1.evaluate(X_test,Y_test)
print('Test set\n  Loss: {:0.3f}\n  F1 Score: {:0.3f}'.format(f1[0],f1[1]))

# create a line graph to show the training and testing loss
plt.title('Loss')
plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='test')
plt.legend()
plt.show();

# create a line graph to show the training and testing accuracy
plt.title('F1 Score')
plt.plot(history.history['get_f1'], label='train')
plt.plot(history.history['val_get_f1'], label='test')
plt.legend()
plt.show();

"""**LSTM Tuned (F1 Score)**"""

# set up a sequential model for the f1 scores
model_f1 = tf.keras.Sequential()
model_f1.add(tf.keras.layers.Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))
model_f1.add(tf.keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))
model_f1.add(tf.keras.layers.LSTM(64, return_sequences=True))
model_f1.add(tf.keras.layers.Dense(32, activation='relu'))
model_f1.add(tf.keras.layers.LSTM(16, return_sequences=True))
model_f1.add(tf.keras.layers.SpatialDropout1D(0.2))
model_f1.add(tf.keras.layers.Flatten())
model_f1.add(tf.keras.layers.Dense(2, activation='relu'))
# compile the model using the f1 metric
model_f1.compile(loss='binary_crossentropy', optimizer='adam', metrics=[f1])

# how many iterations and the size of data batches
epochs = 10
batch_size = 64

# train the model using the training data
history = model_f1.fit(X_train, 
                    Y_train, 
                    shuffle=True,
                    epochs=epochs, 
                    batch_size=batch_size,
                    validation_split=0.1)

"""**GRU Tuned (F1 Score)**"""

# set up a sequential model for the f1 scores
model_f1 = tf.keras.Sequential()
model_f1.add(tf.keras.layers.Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))
model_f1.add(tf.keras.layers.GRU(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))
model_f1.add(tf.keras.layers.GRU(64, return_sequences=True))
model_f1.add(tf.keras.layers.Dense(32, activation='relu'))
model_f1.add(tf.keras.layers.GRU(16, return_sequences=True))
model_f1.add(tf.keras.layers.SpatialDropout1D(0.2))
model_f1.add(tf.keras.layers.Flatten())
model_f1.add(tf.keras.layers.Dense(2, activation='relu'))
# compile the model using the f1 metric
model_f1.compile(loss='binary_crossentropy', optimizer='adam', metrics=[f1])

# how many iterations and the size of data batches
epochs = 10
batch_size = 64

# train the model using the training data
history = model_f1.fit(X_train, 
                    Y_train, 
                    shuffle=True,
                    epochs=epochs, 
                    batch_size=batch_size,
                    validation_split=0.1)

"""**Default LSTM (Accuracy Score)**"""

# set up a sequential model for the accuracy scores
model = tf.keras.Sequential()
model.add(tf.keras.layers.Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))
model.add(tf.keras.layers.SpatialDropout1D(0.2))
model.add(tf.keras.layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2))
model.add(tf.keras.layers.Dense(2, activation='softmax'))
# compile the model using the accuracy metric
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

epochs = 5
batch_size = 64

history = model.fit(X_train, 
                    Y_train, 
                    epochs=epochs, 
                    batch_size=batch_size,
                    validation_split=0.1,
                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])

# find the loss and accuracy of the network
accr = model.evaluate(X_test,Y_test)
print('Test set\n  Loss: {:0.3f}\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))

# create a line graph to show the training and testing loss
plt.title('Loss')
plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='test')
plt.legend()
plt.show();

# create a line graph to show the training and testing accuracy
plt.title('Accuracy')
plt.plot(history.history['accuracy'], label='train')
plt.plot(history.history['val_accuracy'], label='test')
plt.legend()
plt.show();



# set up a sequential model for the f1 scores
model_f1 = tf.keras.Sequential()
model_f1.add(tf.keras.layers.Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))
model_f1.add(tf.keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))
model_f1.add(tf.keras.layers.LSTM(64, return_sequences=True))
model_f1.add(tf.keras.layers.Dense(32, activation='relu'))
model_f1.add(tf.keras.layers.LSTM(32, return_sequences=True))
#model_f1.add(tf.keras.layers.SpatialDropout1D(0.2))
model_f1.add(tf.keras.layers.LSTM(16, return_sequences=True))
model_f1.add(tf.keras.layers.Flatten())
model_f1.add(tf.keras.layers.Dense(2, activation='relu'))
# compile the model using the f1 metric
model_f1.compile(loss='binary_crossentropy', optimizer='adam', metrics=[f1])

# how many iterations and the size of data batches
epochs = 10
batch_size = 64

# train the model using the training data
history = model_f1.fit(X_train, 
                    Y_train, 
                    shuffle=True,
                    epochs=epochs, 
                    batch_size=batch_size,
                    validation_split=0.1)



"""**DistilBert**"""

!pip install transformers==2.10.0

!pip install simpletransformers

from simpletransformers.classification import ClassificationModel
from sklearn.model_selection import train_test_split

# Create a ClassificationModel
model = ClassificationModel('distilbert', 'distilbert-base-uncased', num_labels=2, use_cuda=False)

tweets_df['tweet'] = tweets_df['tweet'].str.lower()

tweets_df.head()

xtrain, ytrain, xvalid, yvalid = train_test_split(tweets_df, tweets_df['subtask_b'], test_size=0.2)

train_df = pd.DataFrame(xtrain)
eval_df = pd.DataFrame(ytrain)

# Train the model
model.train_model(xtrain)

from sklearn.metrics import f1_score, accuracy_score


def f1_multiclass(labels, preds):
    return f1_score(labels, preds, average='macro')
    
result, model_outputs, wrong_predictions = model.eval_model(eval_df, f1=f1_multiclass, acc=accuracy_score)

result

"""**Bert**"""

# Create a ClassificationModel
model_bert = ClassificationModel('bert', 'bert-base-uncased', num_labels=2, use_cuda=False)

xtrain, ytrain, xvalid, yvalid = train_test_split(tweets_df, tweets_df['subtask_b'], test_size=0.2)

train_df = pd.DataFrame(xtrain)
eval_df = pd.DataFrame(ytrain)

# Train the model
model_bert.train_model(xtrain)

from sklearn.metrics import f1_score, accuracy_score

def f1_multiclass(labels, preds):
    return f1_score(labels, preds, average='macro')
    
result, model_outputs, wrong_predictions = model_bert.eval_model(eval_df, f1=f1_multiclass, acc=accuracy_score)

result

"""**Flair**"""

!pip install flair

import flair
import torch

data = pd.read_csv("drive/My Drive/OLIDv1.0/olid-training-v1.0.tsv", encoding='latin-1', error_bad_lines=False).sample(frac=1).drop_duplicates()
 
data = tweets_df[['tweet', 'subtask_b']].rename(columns={"tweet":"text", "subtask_b":"labels"})
 
data['labels'] = '__labels__' + data['labels'].astype(str)
 
data.iloc[0:int(len(data)*0.8)].to_csv('train.csv', sep='\t', index = False, header = False)
data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv('test.csv', sep='\t', index = False, header = False)
data.iloc[int(len(data)*0.9):].to_csv('dev.csv', sep='\t', index = False, header = False);

from flair.data import Corpus
from flair.datasets import CSVClassificationCorpus

data_folder = ''
column_name_map = {0: "text", 1: "labels"}

corpus: Corpus = CSVClassificationCorpus(data_folder,
                                         column_name_map,
                                         skip_header=False,
                                         delimiter='\t') 
label_dict = corpus.make_label_dictionary()
len(corpus.dev)

from flair.data import Corpus
from flair.datasets import TREC_6
from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings
from flair.models import TextClassifier
from flair.trainers import ModelTrainer


# 1. get the corpus
#corpus: Corpus = TREC_6()

# 2. create the label dictionary
label_dict = corpus.make_label_dictionary()

# 3. make a list of word embeddings
word_embeddings = [WordEmbeddings('en-twitter')]

# 4. initialize document embedding by passing list of word embeddings
# Can choose between many RNN types (GRU by default, to change use rnn_type parameter)
document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=256)

# 5. create the text classifier
classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)

# 6. initialize the text classifier trainer
trainer = ModelTrainer(classifier, corpus)

# 7. start the training
trainer.train('resources/taggers/trec',
              learning_rate=0.1,
              mini_batch_size=32,
              anneal_factor=0.5,
              patience=5,
              max_epochs=10)

from flair.data import Sentence
classifier = TextClassifier.load('resources/taggers/trec/best-model.pt')

# create example sentence
sentence = Sentence('i love you')

# predict class and print
classifier.predict(sentence)

print(sentence.labels)

"""**Rescaling the Data with Tf-idf**"""

text_train, y_train = tweets_df.tweet, tweets_df.subtask_b

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import GridSearchCV
pipe = make_pipeline(TfidfVectorizer(min_df=5),
                     LogisticRegression())
param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10]}
grid = GridSearchCV(pipe, param_grid, cv=5)
grid.fit(text_train, y_train)

from sklearn.model_selection import GridSearchCV
vectorizer = grid.best_estimator_.named_steps["tfidfvectorizer"]
X_train = vectorizer.transform(tweets_df['tweet'])
max_value = X_train.max(axis=0).toarray().ravel()
sorted_by_tfidf = max_value.argsort()
feature_names = np.array(vectorizer.get_feature_names())

print("Features with the lowest tfidf: \n{}".format(
    feature_names[sorted_by_tfidf[:20]]
))

print("Features with the highest tfidf: \n{}".format(
    feature_names[sorted_by_tfidf[-20:]]
))

!pip install mglearn

import mglearn
mglearn.tools.visualize_coefficients(
    grid.best_estimator_.named_steps["logisticregression"].coef_,
    feature_names, n_top_features=40
)

"""**Spacy**"""

import spacy
import sklearn
import nltk

en_nlp = spacy.load('en')
stemmer = nltk.stem.PorterStemmer()

def compare_normalization(doc):
  doc_spacy = en_nlp(doc)
  print("Lemmenisation:")
  print([token.lemma_ for token in doc_spacy])
  print("Stemming:")
  print([stemmer.stem(token.norm_.lower()) for token in doc_spacy])

import re
regexp = re.compile('(?u)\\b\\w\\w+\\b')

en_nlp = spacy.load('en', disable=['parser', 'ner'])
old_tokenizer = en_nlp.tokenizer

en_nlp.tokenizer = lambda string: old_tokenizer.tokens_from_list(
    regexp.findall(string)
)

def custome_tokenizer(document):
  doc_spacy = en_nlp(document)
  return [token.lemma_ for token in doc_spacy]

lemma_vect = CountVectorizer(tokenizer=custome_tokenizer, min_df=5)

X_train_lemma = lemma_vect.fit_transform(text_train)
print("X_train_lemma.shape: {}".format(X_train_lemma.shape))

vect = CountVectorizer(min_df=5).fit(text_train)
X_train = vect.transform(text_train)
print("X_train.shape: {}".format(X_train.shape))

from sklearn.model_selection import StratifiedShuffleSplit
param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}
cv = StratifiedShuffleSplit(n_splits=5, test_size=0.99, train_size=0.01, random_state=0)
grid = GridSearchCV(LogisticRegression(),param_grid, cv=cv)
grid.fit(X_train, y_train)
print("Best cross-validation score (Standard CountVectorizer): {:.3f}".format(grid.best_score_))

grid.fit(X_train_lemma, y_train)
print("Best cross-validation score (Lemmatization): {:.3f}".format(grid.best_score_))

"""**Latent Dirichlet Allocation**"""

vect = TfidfVectorizer(max_features=10000, max_df=.15)
X = vect.fit_transform(text_train)

from sklearn.decomposition import LatentDirichletAllocation
lda = LatentDirichletAllocation(n_components=10, learning_method='batch', max_iter=25, random_state=0)
document_topics = lda.fit_transform(X)

print("lds.components_.shape: {}".format(lda.components_.shape))

sorting = np.argsort(lda.components_, axis=1)[:, ::-1]
feature_names = np.array(vect.get_feature_names())

mglearn.tools.print_topics(topics=range(10), 
                           feature_names=feature_names, 
                           sorting=sorting, 
                           topics_per_chunk=5, 
                           n_words=10)

# Commented out IPython magic to ensure Python compatibility.
# Load the library with the CountVectorizer method
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_style('whitegrid')
# %matplotlib inline
# Helper function
def plot_10_most_common_words(count_data, count_vectorizer):
    import matplotlib.pyplot as plt
    words = count_vectorizer.get_feature_names()
    total_counts = np.zeros(len(words))
    for t in count_data:
        total_counts+=t.toarray()[0]
    
    count_dict = (zip(words, total_counts))
    count_dict = sorted(count_dict, key=lambda x:x[1], reverse=True)[0:10]
    words = [w[0] for w in count_dict]
    counts = [w[1] for w in count_dict]
    x_pos = np.arange(len(words)) 
    
    plt.figure(2, figsize=(15, 15/1.6180))
    plt.subplot(title='10 most common words')
    sns.set_context("notebook", font_scale=1.25, rc={"lines.linewidth": 2.5})
    sns.barplot(x_pos, counts, palette='husl')
    plt.xticks(x_pos, words, rotation=90) 
    plt.xlabel('words')
    plt.ylabel('counts')
    plt.show()
# Initialise the count vectorizer with the English stop words
count_vectorizer = CountVectorizer(stop_words='english')
# Fit and transform the processed titles
count_data = count_vectorizer.fit_transform(tweets_df['tweet'])
# Visualise the 10 most common words
plot_10_most_common_words(count_data, count_vectorizer)

import warnings
warnings.simplefilter("ignore", DeprecationWarning)
# Load the LDA model from sk-learn
from sklearn.decomposition import LatentDirichletAllocation as LDA
 
# Helper function
def print_topics(model, count_vectorizer, n_top_words):
    words = count_vectorizer.get_feature_names()
    for topic_idx, topic in enumerate(model.components_):
        print("\nTopic #%d:" % topic_idx)
        print(" ".join([words[i]
                        for i in topic.argsort()[:-n_top_words - 1:-1]]))
        
# Tweak the two parameters below
number_topics = 10
number_words = 10
# Create and fit the LDA model
lda = LDA(n_components=number_topics, n_jobs=-1)
lda.fit(count_data)
# Print the topics found by the LDA model
print("Topics found via LDA:")
print_topics(lda, count_vectorizer, number_words)